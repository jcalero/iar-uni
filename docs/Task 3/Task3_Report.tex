%%% LaTeX Template
%%% This template is made for project reports
%%%	You may adjust it to your own needs/purposes
%%%
%%% Copyright: http://www.howtotex.com/
%%% Date: March 2011

%%% Preamble
\documentclass[paper=a4, fontsize=12pt]{scrartcl}	% Article class of KOMA-script with 12pt font and a4 format


\usepackage[english]{babel}				% English language/hyphenation
\usepackage[protrusion=true,expansion=true]{microtype}	% Better typography
\usepackage{amsmath,amsfonts,amsthm}			% Math packages
\usepackage[pdftex]{graphicx}				% Enable pdflatex
\usepackage{url}
\usepackage[margin=1.5in]{geometry}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{framed}
\usepackage{listings}

\lstset{
language=Matlab,
basicstyle=\footnotesize,
tabsize=2
}


%%% Custom sectioning (sectsty package)
\usepackage{sectsty}					% Custom sectioning (see below)
\allsectionsfont{\normalfont\scshape}			% Change font of al section commands


%%% Custom headers/footers (fancyhdr package)
\usepackage{fancyhdr}
\pagestyle{fancyplain}
\fancyhead{}						% No page header
%\fancyfoot[L]{\small \url{HowToTeX.com}}		% You may remove/edit this line 
\fancyfoot[C]{}						% Empty
\fancyfoot[R]{\thepage}					% Pagenumbering
\renewcommand{\headrulewidth}{0pt}			% Remove header underlines
\renewcommand{\footrulewidth}{0pt}			% Remove footer underlines
\setlength{\headheight}{13.6pt}


%%% Equation and float numbering
\numberwithin{equation}{section}		% Equationnumbering: section.eq#
\numberwithin{figure}{section}			% Figurenumbering: section.fig#
\numberwithin{table}{section}				% Tablenumbering: section.tab#


%%% Maketitle metadata (Defines how everything above the body should look like: title, header, authors, date, etc..)
\newcommand{\horrule}[1]{\rule{\linewidth}{#1}} 	% Horizontal rule

\title{
\vspace{-1in} 	
\usefont{OT1}{bch}{b}{n}
\normalfont \normalsize \textsc{University of Edinburgh - School of Informatics}
\\ [25pt]
\horrule{0.5pt} \\[0.4cm]
\large IAR - Task 3 Report \\
\horrule{1pt} \\[0.5cm]
}
\author{
  \normalfont \normalsize
  Jakob Calero - s0948339\\[-3pt]\normalsize
  Samuel Neugber - s0821562\\[-3pt]\normalsize
  \today
}
\date{}


%%% Begin document
\begin{document}
\maketitle					% Insert the title here
\section{Abstract}
Even with the limited information which can be extracted from the Khepera II robot's IR-sensors, particle filters can successfully estimate the location and orientation of said robot in a static arena. Using potential field navigation and stochastic sampling of positions in the arena, in combination with the localization from the particle filter, we were able to reliably find marked positions, return to the starting position and repeat this process several times in a few minutes. The system does have a few drawbacks, including speed of execution, some navigation fallacies as well as uncertainty of finding market positions due to stochastic sampling, but overall the methods we implemented work well together and get the job done as specified.

\section{Introduction}
In this final assignment we are given the task to put together our experience from previous tasks in navigation and control and add it to a more complex goal-based navigation and localisation problem based on a fixed map environment.

The task asks us to emulate a basic "collection" behaviour, where our Khepera II robot is tasked to navigate through a known environment searching for possible "food sources" and return collected food from the sources to a fixed home position. In order to do so, the robot has to reliably track its position to be capable of navigating and exploring the map, avoid obstacles, gather the food, return to the correct home position and be able to return to previous food positions again.

This leads us to the three main problems in this task; how to implement localization, navigation and goal directed behaviour. Underlying all three of these problems a decision had to be made about the representation of the known and static map of the arena and the method to be used for location prediction of the robot pose. We narrowed down our options based on our experience in the course, our previous experience in robotics and the task at hand to the following methods:

\begin{itemize}
\item Map representation 
\begin{itemize}
\item A discrete map of occupancy grids
\item A continuous representation using point-to-point lines
\end{itemize}
\item Localisation
\begin{itemize}
\item Extended Kalman filter
\item Particle filter
\end{itemize}
\item Navigation
\begin{itemize}
\item A* path finding
\item Potential field
\end{itemize}
\item Planning
\begin{itemize}
\item Fixed points the robot should visit
\item A coverage heuristic of how much of the map has been explored
\item Stochastic exploration
\end{itemize}
\end{itemize}

From our previous task (\emph{Task 2 - Robot can combine behaviours}) we had already implemented a simple navigation system with differential wheel movements given a direction in absolute angles. An easy extension to that control behaviour was to create a potential field to calculate this directional angle, which lead to us making that choice for navigation. This lead to the choice of using a continuous map representation as this makes more sense when for a potential field and allows us to be more precise when specifying the map and robot coordinates.

For localisation, undoubtedly the most difficult (and arguably most significant) task in this assignment, we rather quickly gravitated to the choice of using a particle filter, partially due to the fact that it's relatively easy to implement and that, given enough samples, we hope to reach a better estimate than using an Extended Kalman Filter. Our work on the particle filter in this task is mainly extended from an online resource by student Danilio Oliveira at P. Norvig's and S. Thrun's online course, \url{http://www.ai-class.com}. \cite{oliveira}\cite{aiclass}

Exploration was chosen to be entirely random mainly due to simplicity of implementation and the nature of the task. We had no information about the food sources location, spread or amount so we had very little to base our exploration on and found that, in the relatively small arena, a stochastic exploration method would be sufficient. Food collection was chosen to be rather straight forward where the robot simply takes home the first food source it finds and later returns to it for more food essentially abandoning exploration, but changing its main food source if another source is found on the way to or from the previous food source. Additionally, if, after a time at the predicted food source location, the food source is not "detected" (this is done by covering all the robots IR sensors at once) the robot will abandon this food source and resume exploration.

\section{Methods} 
\subsection{Map Representation}
The map we used for this task is represented as line equations, given the start and end points of the walls of each obstacle. This implementation has the benefit of giving us a much higher precision to work with and that no translation of robot position to discrete space has to be performed, but suffers from the problem of relatively computationally expensive line intersections, particularly when combined with particle filtering. Essentially each object on the map is represented by a set of line segments and distances to objects are calculated with line intersections between a vector drawn from the source to the closest line in its path. This implementation is entirely \emph{as is} from D. Oliveira's particle filter implementation.\cite{oliveira}

The arena itself is a 1.44m by 0.96m flat surface, with enclosing walls and multiple, fixed obstacles of various shapes and sizes. (\emph{\ref{potfieldmap}}) All our units throughout all our calculations are translated to millimetres which gives us high precision and an easy to use metric.

\subsection{Localisation}
Building on the work of D. Oliveira particle filter simulation instead of building a particle filter from scratch allowed us to save time and learn from the process. Much of it was heavily modified however and had to be adapted it to our needs.

The particle filter uses the reading from the robots 8 IR sensors as its only predictor for calculating the probability of 200 particles. Movement of the particles are based on the values given by our odometry and not by the robot commands, under the assumption that odometry is accurate enough in short time intervals like those of our robot control loop (averages on 482ms over 10 3 minute runs, see \ref{exptable}).

To find the probability of each particle, D. Oliveiras particle filter used a distance metric which was computed as the distance between 'sensors', spread evenly around the 'robot', to the closest wall. This method was close to how our robot would sense the world but required some adaptation. 

While the particle line intersections return distances in millimetres, the robot IR sensors return values much less linearly (see \ref{irvals}) so we had to find some function to map sensory information to distance in millimetres. We expected either logarithmic or exponential regression fitting to allow us to fit a function over the sensor values but found little success (\ref{fitgraph})\cite{wolfram}. We therefore decided to instead measure values in 1cm intervals and linearly interpolate between them giving us close enough approximations in the distances between our measured values. Due to the low range of the sensors, we decided to cap the values at 7cm, seeing that very little information can be gained from sensor values at further distances (\ref{irvals}). This also allowed us to limit the amount of line intersections to be calculated during particle probability estimations to only be performed on objects closer than 7cm drastically reducing computation speed. 

The movement of particles is governed by a random variable in the normal distribution with a a relatively small standard deviation relative to the robot movements since last loop iteration. This is a deviation from D. Oliveiras work which used a constant standard deviation relatively large to it's movement space. The particles are resampled once every 10th control loop iteration, making it on average once every 4.82 seconds (\(10* 0.482\text{ seconds}\)) and given our experience with odometry, on a run of this length of time, odometry is generally fairly accurate allowing us to use a smaller standard deviation and the smaller the movement the higher the accuracy and the lower the standard deviation.

\subsection{Potential Field}
To navigate through the arena, we had to find a method which would work with our continuous map, which meant that certain methods like A* path search were out of the question. The potential field method we use was a close solution since we already had a movement method from the last task which takes an angle relative to the robot and translates it into relative wheel speeds (Motor Schema Architecture, Arkin 1989). Again, due to the fact that our map is not discretised, we found it easier to not precompute the potential field, but instead calculate the vector, which gives the direction the robot should move in, in real-time.

Our potential field method uses attracting forces from our target sources and repulsing forces from obstacles to calculate a vector which represents the direction the robot should move into. To easily calculate the repulsing forces from object, we place points along their boundary walls with a 1cm spacing (\ref{potfieldmap}) and then calculate the difference vector between them and the robot position, while increasing the influence of the obstacles exponentially, the closer the robot gets to them. The attracting force of the target on the other hand – the target being either a target point for exploration, the home position, or a known food source \textendash is scaled linearly across the map, so that the robot always has some goal to pursue. 

In the last task, we had already developed a method to translate an angle relative to the robot into relative wheel speeds, although for the last task this angle was computed from the weighted average of the ambient light sensors. Given the angle from the our potential field, we simply inhibit one of the wheels according to the direction and size of the angle.

Overall, this method is quite simple, relatively quick, since it only needs to check a few points, and relies only on a few variables – the distribution of the repelling points, their repelling force as well as the attracting force of the target – so configuration was finished within a few test runs.

\subsection{Control}
The robot is controlled by a simple hybrid architecture with two deliberative, high level, components, "explore" and "collect food", and two reactive, low level, components, "navigate/go to target" and "avoid obstacle". The high level components are chosen based on the simple condition of whether the robot knows where there is food and whether it has food in its "possession". Both conditions can change to either state throughout the robot lifetime by "forgetting" a food location, done via time-out at predicted food location, and dropping of a food item at the home location. Navigation will take care of executing the plan by performing the wheel operations based on the response from the potential field and a baseline obstacle avoidance, adapted from our previous task in this course (Task 1 - Robot avoids obstacles and follows walls.), will reactively force movement away from an obstacle if travelled to close to it. \ref{architecture}
\subsubsection{Target planning}
When the robot starts from its initial position, the control code will first set a random position as the target so that the robot starts exploring. If the robot is unable to reach the target within 15 seconds, a new random position within the arena is chosen. If the robot encounters a food source during exploration – as specified by blocking all of its IR-sensors, "the collection event"– it will store that position and return home. Once it has reached home it will return to the last food position and repeat the process unless it finds a new food position on it's path. If it thinks it's reached the food position but the collection event is not triggered, in 5 seconds intervals it will place a new target at a random position within 4 cm radius around the food source to explore around that position. If after 35 seconds since it first arrived at the food source the collection event is still not triggered the food source will be removed from the robots memory and the robot will resume exploration will either move to another known food position or resume exploration of the map. 
\subsection{Experimental methods}
To record and evaluate the performance of our robot in the given task we performed 10 subsequent runs of 3 minutes each in the actual arena to be used during the demonstration. The robot was however artificially constricted to the lower half of the arena to mitigate for the shorter runs. There were 5 food source locations reachable by the robot. The home position was a circle of approximately 11 cm radius and the robot was considered home if it stopped and flashed its LED lights when fully inside the circle. Food sources were spots on the arena of approximately 3mm radius and the food collection event was performed when any part of the robot passed on top of them. "Points" were calculated by giving 1 point for each food source reached/found and 5 points for each food item returned home.
\section{Results}
GRAPH

Once a food source was found, our robot performed well, with an average of 10 points over those runs. However, only 40\% of the runs actually found any food source at all lowering the point average to 4 points per run.

The particle filter showed very good results however throughout all tests, giving an average 93\% correct prediction.

On average each timestep (control loop iteration) took 0.546s, with an average of 1.187 for the resampling once every 10 timesteps and 0.482s the rest of loop. The resampling time was largely dominated by the calculation of predicted IR values by line intersection at 4.9ms per particle, which at 200 particles adds up to 980ms, ~82.6\% of the total timestep. The times were calculated by timing each component of each run and averaging over all the runs.
\section{Discussion}

\begin{verbatim}
•	What worked
◦	Finds itself in X\% of cases when next to a wall (can we even quantify this at all?)
◦	Potential field navigation can result in pretty smooth movement
•	Issues
◦	Assignment of robot position to wrong particle when not next to a wall
▪	In general: Not enough information from IR sensors in these cases to make a good prediction
◦	Particles moving into objects
◦	Speed/Performance of particle filter
◦	Potential field navigation can get stuck when vectors add up straight into objects
\end{verbatim}

This was one of the main issues in our test usually finding a food source within (X amount of time), returning it home in Y\% and finding it again in Z\% of cases. The three main issues we had were that resampling of the particles took too long, that our simplistic potential field navigation did not really do any sophisticated path finding and that there existed too much ambiguity from the sensor values if the robot was not next to any wall.

\subsection{Particle Filter}
We mitigated the issue of the resampling taking up that much time by reducing the number of walls the prediction of the IR-values for each particle would take into account as well as only resampling every ten loop iterations. Still, having to stop every couple of seconds to give the robot 'time to think', is suboptimal and reduced the area of the map our robot was able to cover in a given time, ultimately restricting us in the strategies we could pursue. What we did learn from having to work around the issue and resampling only every so often on the other hand, was that this can actually be beneficial since the more often the robot resamples the particles while being clear of any walls and thus having no inputs to the IR-sensors reduces the amount of misplacement of particles and gave us a higher accuracy over longer runtimes.

In general, the particle filter worked well, as can be seen by the deviation over a number of timesteps in (PICTURES after 30s, 1min, 2min, 5min or something). It updated the position quite reliably and even though it sometimes got it wrong when too little data could be gathered over too little time, it corrected itself in most cases as soon as it hit a wall and was able to gather more telling data from the IR-sensors.

\subsection{Potential field navigation}
The potential field navigation we had used again worked well in most cases, but had some clear drawbacks. It did make the robot reliably avoid obstacles and move between them, but once a larger obstacle directly blocked the path to the target, the way we calculated the vectors would point the robot straight towards the obstacle instead of around it. One case which clearly shows this to be a problem, is the L-shaped obstacle as seen in (DIAGRAM). With the robot coming from the bottom and the target being on the other side, it would attempt to move straight into the wall until the control loop would deem the target unreachable after a certain amount of time and set a new one.

For all intents and purposes, the functionality it provided was reasonable and its simplicity meant that we did not have to spend much time on tweaking it. Although the down-sides were clear, the navigation worked well together with the way we set and reset targets and we never felt that we lost too much time by trying to 'move through' an obstacle.

\subsection{Overall}
can't think anymore, too much coffee...


\textbf{(This goes in discussion) POSSIBLE EXTENSIONS}

	Dynamic Particle Filter – higher deviation if certainty is low, fewer particles if certainty is high, randomize particles if certainty is very low.
	Potential field modifications, function around objects

\begin{thebibliography}{9}
\bibitem{oliveira}
  Danilo Oliveira,
  \emph{Particle Filter Implementation in Matlab},
  ai-class.com,
  2011,
  \url{http://www.youtube.com/watch?v=sjny6-lVtb4}.
\bibitem{aiclass}
  Peter Norvig, Sebastian Thrun,
  2012,
  \emph{Introduction to Artificial Intelligence},
  Udacity, Stanford Engineering,
  \url{http://www.ai-class.com}.
\end{thebibliography}
\section{Appendix}
\subsection{Code listing}

%%% End document
\end{document}
